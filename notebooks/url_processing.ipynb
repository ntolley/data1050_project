{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Products URL is considered the \"gold-standard\". We need to look through the log file to 1) find corrupted URL's, and 2) write and algorithm to correct them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products URL should be considered \"gold standard\"\n",
    "\n",
    "products_df = pd.read_csv('../data/products.csv')\n",
    "log_df = pd.read_csv('../data/log2.csv',\n",
    "                     names=['sentiment', 'publication_URL', 'product_URL',\n",
    "                     'clickORnot', 'gender', 'age_group'])\n",
    "product_categories = pd.read_csv('../data/product_categories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "*Some of the Product_URLs in the log file might have been corrupted. Write a Python (or PySpark) procedure to determine which Product_URLs are corrupted. Let us assume that if a Product_url in the log file doesn’t occur in the products table, it is regarded as corrupted. Using this procedure identify and list the corrupted URLs. (10)*\n",
    "\n",
    "The code below uses the simple list matching function `np.in1d()` to quickly identify which URLs in the log file are not present in hte products file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>publication_URL</th>\n",
       "      <th>product_URL</th>\n",
       "      <th>clickORnot</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.cbsnews.com/</td>\n",
       "      <td>https://haier.com/refrigermtors</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://mashable.com/</td>\n",
       "      <td>https://sony.comftelevisions</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>juvenile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.thedailybeast.com/</td>\n",
       "      <td>https://lg.com/gashers</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>middle-age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.cnn.com/</td>\n",
       "      <td>https://leks.com/jeans</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.nytimes.com/</td>\n",
       "      <td>https://InstantPot.con/cookers</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.usnews.com/</td>\n",
       "      <td>http://nejoK.co/blenders</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9773</th>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.nbcnews.com/</td>\n",
       "      <td>https://maytag.cpm/washers</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>middle-age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9845</th>\n",
       "      <td>positive</td>\n",
       "      <td>https://www.foxnews.com/</td>\n",
       "      <td>https://guessmcom/perfumes</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>middle-age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>neutral</td>\n",
       "      <td>https://www.usnews.com/</td>\n",
       "      <td>https://samsuag.com/televisions</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>young</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>negative</td>\n",
       "      <td>https://www.theguardian.com/us</td>\n",
       "      <td>https://InstantPotycom/cookers</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>middle-age</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                 publication_URL  \\\n",
       "83    negative        https://www.cbsnews.com/   \n",
       "109    neutral           https://mashable.com/   \n",
       "123   negative  https://www.thedailybeast.com/   \n",
       "171    neutral            https://www.cnn.com/   \n",
       "203    neutral        https://www.nytimes.com/   \n",
       "...        ...                             ...   \n",
       "9729   neutral         https://www.usnews.com/   \n",
       "9773  negative        https://www.nbcnews.com/   \n",
       "9845  positive        https://www.foxnews.com/   \n",
       "9881   neutral         https://www.usnews.com/   \n",
       "9951  negative  https://www.theguardian.com/us   \n",
       "\n",
       "                          product_URL  clickORnot  gender   age_group  \n",
       "83    https://haier.com/refrigermtors           0  female       young  \n",
       "109      https://sony.comftelevisions           1  female    juvenile  \n",
       "123            https://lg.com/gashers           0  female  middle-age  \n",
       "171            https://leks.com/jeans           0  female      senior  \n",
       "203    https://InstantPot.con/cookers           1  female       young  \n",
       "...                               ...         ...     ...         ...  \n",
       "9729         http://nejoK.co/blenders           0    male      senior  \n",
       "9773       https://maytag.cpm/washers           1    male  middle-age  \n",
       "9845       https://guessmcom/perfumes           1  female  middle-age  \n",
       "9881  https://samsuag.com/televisions           0  female       young  \n",
       "9951   https://InstantPotycom/cookers           0    male  middle-age  \n",
       "\n",
       "[216 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull out URLs and strip leading/lagging whitespace\n",
    "product_urls = products_df['product_URL'].str.strip().values\n",
    "log_urls = log_df['product_URL'].str.strip().values\n",
    "\n",
    "# Check which elements of log_urls are NOT an exact match in product_urls\n",
    "url_mask = ~np.in1d(log_urls, product_urls)\n",
    "log_df[url_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "For each corrupted URL what will you do with it? Don’t assume that for each corrupted URL the correct approach is to delete that log entry. What if the URL contained ‘.cam’ instead of ‘.com’ but otherwise corresponded with a URL in the ‘products’ table? In that case the proper approach would be to correct the URL. In other cases, the URL might be so corrupted that the best approach would be to delete that log entry (the entire row). Describe your approach to dealing with corrupted URLs. That is, describe your approach to determining that a URL is too corrupted to be rescued. It must describe a) a procedure for determining the degree to which the URL is corrupted, b) a threshold for determining in terms of this degree of corruption whether it can be corrected, and c) for those which can be corrected, identifying its corrected form. For extra credit implement this in a Python (or PySpark) program. (25 + 20 points for extra-credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ntolley/Grad_School/DSI/data1050_project/notebooks/url_processing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ntolley/Grad_School/DSI/data1050_project/notebooks/url_processing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m log\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log' is not defined"
     ]
    }
   ],
   "source": [
    "# Taken from: https://stackoverflow.com/questions/3809401/what-is-a-good-regular-expression-to-match-a-url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0efaeb1f57b331682f483338b2ece2b224a46046d22ccab062f7cb485953279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
